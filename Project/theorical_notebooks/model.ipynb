{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] : add [/home/widium/Programming/AI/Vision-Transformer/Project] to Python path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def add_top_directory_to_python_path(top_directory : str = \"Project\"):\n",
    "    \"\"\"\n",
    "    Add top directory of Project to Python Path for managing import between directory\n",
    "\n",
    "    Args:\n",
    "        top_directory (str, optional): top folder of project. Defaults to \"Project\".\n",
    "    \"\"\"\n",
    "    current_dir_path = Path(os.getcwd())\n",
    "    current_dir_name = current_dir_path.stem\n",
    "    \n",
    "    while (current_dir_name != top_directory):\n",
    "        current_dir_path = current_dir_path.parent\n",
    "        current_dir_name = current_dir_path.stem\n",
    "    \n",
    "    sys.path.append(str(current_dir_path))\n",
    "    print(f\"[INFO] : add [{current_dir_path}] to Python path\")\n",
    "\n",
    "add_top_directory_to_python_path(top_directory=\"Project\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "\n",
    "from modeling.builder.image_tokenization import ImageTokenizer\n",
    "from modeling.builder.tokens_processing import ClassTokenPrepender\n",
    "from modeling.builder.tokens_processing import PositionalEmbedding\n",
    "\n",
    "class VisionTransformerModel(Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        patch_size : int = 16,\n",
    "        color_channels : int = 3,\n",
    "        embedding_size : int = 768):\n",
    "        \n",
    "        self.image_tokenizer = ImageTokenizer(\n",
    "            patch_size=patch_size,\n",
    "            color_channels=color_channels,\n",
    "            embedding_size=embedding_size,\n",
    "        )\n",
    "        \n",
    "        self.class_token_prepender = ClassTokenPrepender(\n",
    "            embedding_size=embedding_size,\n",
    "        )\n",
    "        \n",
    "        self.positional_embedding = PositionalEmbedding(\n",
    "            nbr_token=_,\n",
    "            embedding_size=embedding_size,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, x : Tensor)->Tensor:\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VisionTransformerModel' object has no attribute '_modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.8/site-packages/IPython/core/formatters.py:706\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    699\u001b[0m stream \u001b[39m=\u001b[39m StringIO()\n\u001b[1;32m    700\u001b[0m printer \u001b[39m=\u001b[39m pretty\u001b[39m.\u001b[39mRepresentationPrinter(stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnewline,\n\u001b[1;32m    702\u001b[0m     max_seq_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_seq_length,\n\u001b[1;32m    703\u001b[0m     singleton_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingleton_printers,\n\u001b[1;32m    704\u001b[0m     type_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype_printers,\n\u001b[1;32m    705\u001b[0m     deferred_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 706\u001b[0m printer\u001b[39m.\u001b[39;49mpretty(obj)\n\u001b[1;32m    707\u001b[0m printer\u001b[39m.\u001b[39mflush()\n\u001b[1;32m    708\u001b[0m \u001b[39mreturn\u001b[39;00m stream\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.8/site-packages/IPython/lib/pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m                         \u001b[39mreturn\u001b[39;00m meth(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[1;32m    408\u001b[0m                 \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m                         \u001b[39mand\u001b[39;00m callable(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m__repr__\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m--> 410\u001b[0m                     \u001b[39mreturn\u001b[39;00m _repr_pprint(obj, \u001b[39mself\u001b[39;49m, cycle)\n\u001b[1;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_pprint(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[1;32m    413\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.8/site-packages/IPython/lib/pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[39m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[39m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39;49m(obj)\n\u001b[1;32m    779\u001b[0m lines \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msplitlines()\n\u001b[1;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m p\u001b[39m.\u001b[39mgroup():\n",
      "File \u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:2006\u001b[0m, in \u001b[0;36mModule.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2004\u001b[0m     extra_lines \u001b[39m=\u001b[39m extra_repr\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m   2005\u001b[0m child_lines \u001b[39m=\u001b[39m []\n\u001b[0;32m-> 2006\u001b[0m \u001b[39mfor\u001b[39;00m key, module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_modules\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   2007\u001b[0m     mod_str \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39m(module)\n\u001b[1;32m   2008\u001b[0m     mod_str \u001b[39m=\u001b[39m _addindent(mod_str, \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1268\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VisionTransformerModel' object has no attribute '_modules'"
     ]
    }
   ],
   "source": [
    "ViT = VisionTransformerModel()\n",
    "\n",
    "ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
