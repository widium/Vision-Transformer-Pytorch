{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Processing\n",
    "\n",
    "### Index \n",
    "- [Create and Append Class Token to Patch Token ](#create-and-append-class-token-to-patch-token)\n",
    "- [Learnable Positional Embedding](#learnable-positional-embedding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Append Class Token to Patch Token \n",
    "![](https://i.imgur.com/Vwk2hbe.png)\n",
    "\n",
    "- The class token serves as a **summary of global information extracted from patches during encoding** and\n",
    "provides additional information for classification tasks.\n",
    "- Create a learnable class token vector with `Parameter` and prepend it to the sequence of patch embedding vectors with `torch.cat()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "from torch.nn import Parameter\n",
    "\n",
    "class ClassTokenPrepender(Module):\n",
    "    \"\"\"\n",
    "    Create a learnable class token vector and prepend it to the sequence of patch embedding vectors.\n",
    "    The class token serves as a summary of global information extracted from patches during encoding and\n",
    "    provides additional information for classification tasks.\n",
    "\n",
    "    Args:\n",
    "        embedding_size (int): embedding size of other embedding vectors \n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_size : int):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        class_token_vector = torch.randn(\n",
    "            size=(1, 1, self.embedding_size)\n",
    "        )\n",
    "\n",
    "        self.class_token_vector = Parameter(\n",
    "            data=class_token_vector,\n",
    "            requires_grad=True #  convert to learnable parameters\n",
    "        )\n",
    "    \n",
    "    def forward(self, x : Tensor)->Tensor:\n",
    "        \"\"\"\n",
    "        Prepend the learnable class token vector to the input tensor. \n",
    "        If the input tensor has more than one batch, \n",
    "        the class token vector is expanded to match the batch size.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): input tensor of size [batch_size, nbr_token, embedding_size]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: input tensor with the class token prepended, \n",
    "                    resulting in size [batch_size, nbr_token + 1, embedding_size]\n",
    "\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        if (batch_size > 1):\n",
    "            class_token_vector = self.class_token_vector.expand(batch_size, 1, self.embedding_size)\n",
    "        else :\n",
    "            # don't repeat the token\n",
    "             class_token_vector = self.class_token_vector\n",
    "        \n",
    "        x = torch.cat(tensors=[class_token_vector, x], dim=1) # Preprend the class token in input tensor\n",
    "        \n",
    "        return (x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 197, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_prepender = ClassTokenPrepender(embedding_size=768)\n",
    "dummy_tokens = torch.randn(size=(1, 196, 768))\n",
    "\n",
    "tokens_embedding = token_prepender(dummy_tokens)\n",
    "tokens_embedding.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learnable Positional Embedding\n",
    "[Return to Index](#index)\n",
    "\n",
    "![](https://i.imgur.com/9Mv4UVO.png)\n",
    "- Positional embeddings are learnable vectors,\n",
    "- initialized randomly and updated during training,\n",
    "- that represent the **spatial locations** of patch tokens in an image,\n",
    "- **Help the Self Attention mechanism to considering patch positions.**\n",
    "- The Positional Embedding must be apply after class token creation this ensure that the model treats the class token as an **integral part of the input sequence and accounts for its position**\n",
    "***\n",
    "- Create Tensor with same size of tokens with Learnable random values\n",
    "- Wrapped into `Parameters` with Gradient Tracking\n",
    "- Use **Element-Wise Addition** between embedding_vectors and positional_embedding_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Parameter\n",
    "\n",
    "class PositionalEmbedding(Module):\n",
    "    \"\"\"\n",
    "    Create learnable positional embeddings representing spatial locations of input tokens.\n",
    "    The positional embeddings have the same size as the input embeddings for effectuate element-wise addition.\n",
    "    This helping the self-attention mecanism to considering tokens position.\n",
    "\n",
    "    Args:\n",
    "        nbr_token (int): nbr of input Embedding Vector (token)\n",
    "        embedding_size (int) : size of input Embedding Vector\n",
    "    \"\"\"\n",
    "    def __init__(self, nbr_token : int , embedding_size : int):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.nbr_token = nbr_token\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        positional_embedding = torch.randn(\n",
    "            size=(1, self.nbr_token, self.embedding_size)\n",
    "        ) \n",
    "\n",
    "        self.positional_embedding = Parameter(\n",
    "            data=positional_embedding,\n",
    "            requires_grad=True #  convert to learnable parameters\n",
    "        )\n",
    "    \n",
    "    def forward(self, x : Tensor)->Tensor:\n",
    "        \"\"\"\n",
    "        Apply positional embeddings to the input tensor by adding them element-wise. \n",
    "        If the input tensor has more than one batch, the positional embeddings are expanded \n",
    "        to match the batch size.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): input tensor of size [batch_size, nbr_token, embedding_size]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: tensor with the same shape as the input tensor, with positional embeddings added element-wise\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        if (batch_size > 1):\n",
    "            positional_embedding = self.positional_embedding.expand(\n",
    "                batch_size,\n",
    "                self.nbr_token, \n",
    "                self.embedding_size\n",
    "            )\n",
    "\n",
    "        else :\n",
    "            # # don't expand the tensor\n",
    "            positional_embedding = self.positional_embedding\n",
    "        \n",
    "        # apply element_wise addition\n",
    "        embedding_vectors = torch.add(x, positional_embedding)\n",
    "\n",
    "        return (embedding_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 197, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_embedder = PositionalEmbedding(nbr_token=197, embedding_size=768)\n",
    "\n",
    "dummy = torch.randn(size=(1, 197, 768))\n",
    "\n",
    "positional_embedder(dummy).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
